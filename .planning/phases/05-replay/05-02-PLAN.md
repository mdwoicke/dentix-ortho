---
phase: 05-replay
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/services/flowiseReplayService.ts
  - backend/src/services/cloud9DirectService.ts
  - backend/src/controllers/testMonitorController.ts
  - backend/src/routes/testMonitor.ts
autonomous: true

must_haves:
  truths:
    - "User can re-send caller messages from a trace through Flowise and compare new tool calls with original"
    - "When Node-RED returns unexpected results, user can test Cloud9 API directly with same parameters to isolate bottleneck"
    - "Comparison report shows differences between original and replayed responses"
  artifacts:
    - path: "backend/src/services/flowiseReplayService.ts"
      provides: "Flowise end-to-end replay by re-sending caller messages"
      contains: "replayThroughFlowise"
    - path: "backend/src/services/cloud9DirectService.ts"
      provides: "Direct Cloud9 API testing with parameters extracted from trace"
      contains: "testCloud9Direct"
  key_links:
    - from: "flowiseReplayService.ts"
      to: "Flowise prediction API"
      via: "HTTP POST to chatflow endpoint"
      pattern: "prediction"
    - from: "cloud9DirectService.ts"
      to: "Cloud9 partner API"
      via: "HTTP POST with XML body"
      pattern: "GetData.ashx"
    - from: "testMonitorController.ts"
      to: "flowiseReplayService.ts"
      via: "replayThroughFlowise call"
      pattern: "replayThroughFlowise"
---

<objective>
Add Flowise end-to-end replay (re-send caller messages) and Cloud9 direct API testing to isolate whether failures originate in tool logic or the upstream Cloud9 API.

Purpose: REPLAY-02 and REPLAY-03 - reproduce integration-layer issues and isolate Cloud9 vs tool logic bottlenecks
Output: Two new services and their API endpoints
</objective>

<execution_context>
@C:\Users\mwoic\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\mwoic\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-replay/05-RESEARCH.md
@backend/src/services/replayService.ts
@backend/src/services/langfuseTraceService.ts
@backend/src/controllers/testMonitorController.ts
@backend/src/routes/testMonitor.ts
@test-agent/src/core/flowise-client.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Flowise replay service and Cloud9 direct test service</name>
  <files>backend/src/services/flowiseReplayService.ts, backend/src/services/cloud9DirectService.ts</files>
  <action>
**flowiseReplayService.ts:**

Create a new service that replays a trace through Flowise:

1. `replayThroughFlowise(traceId: string, flowiseConfigId?: number)` -> `FlowiseReplayResult`
   - Query `langfuse_observations` for the trace to extract caller messages (filter for generation-type observations where input contains user messages, or query `session_analysis` table for transcript)
   - Alternatively, use `callerIntentClassifier` pattern to extract caller turns from the trace transcript
   - Get Flowise chatflow URL from `flowise_configs` table (default config ID 1)
   - Create a new session ID (uuid)
   - Send each caller message sequentially to `POST {flowiseUrl}/api/v1/prediction/{chatflowId}` with `{ question, sessionId, overrideConfig: {} }`
   - Wait 2 seconds between messages (Flowise processing time)
   - Collect all responses including any tool calls visible in the response
   - Compare: list which tool calls were made in replay vs original trace
   - Return `FlowiseReplayResult`: `{ traceId, replaySessionId, messages: Array<{sent, received}>, toolCallComparison: Array<{original, replayed, match}>, limitations: string[] }`

Include limitation note: "Slot availability and cache state will differ from original call. This tests integration logic, not exact reproduction."

Use `node-fetch` or built-in fetch (Node 18+) for HTTP calls. Follow existing patterns in replayService.ts for auth headers.

**cloud9DirectService.ts:**

Create a service that tests Cloud9 API directly:

1. `testCloud9Direct(observationId: string)` -> `Cloud9DirectResult`
   - Query `langfuse_observations` for the observation by ID
   - Extract the input parameters (the JSON body sent to Node-RED)
   - Map the Node-RED endpoint action to the corresponding Cloud9 XML procedure:
     - `GetAvailableAppts` -> `GetOnlineReservations` (with startDate, endDate, schdvwGUIDs)
     - `patient_lookup` -> `GetPortalPatientLookup` (with filter)
     - `create_patient` -> `SetPatient` (with patient fields)
     - `schedule_appointment` -> `SetAppointment` (with appointment fields)
   - Build Cloud9 XML request using the format from CLAUDE.md (namespace `http://schemas.practica.ws/cloud9/partners/`, include ClientID/UserName/Password from env or config)
   - POST to `https://us-ea1-partner.cloud9ortho.com/GetData.ashx` with 200ms delay
   - Parse XML response
   - Compare with the observation's output (what Node-RED returned)
   - Return `Cloud9DirectResult`: `{ observationId, nodeRedResponse, cloud9Response, match, differences: string[], bottleneck: 'cloud9' | 'tool_logic' | 'inconclusive' }`

Use Cloud9 production credentials from existing config (ClientID `b42c51be-2529-4d31-92cb-50fd1a58c084` from CLAUDE.md or env vars). For XML building, use template strings (no xml library needed - the format is simple).
  </action>
  <verify>TypeScript compiles: `cd backend && npx tsc --noEmit`</verify>
  <done>Both services export their main functions and compile. flowiseReplayService sends messages to Flowise. cloud9DirectService sends XML to Cloud9 API.</done>
</task>

<task type="auto">
  <name>Task 2: Add Flowise replay and Cloud9 direct test API endpoints</name>
  <files>backend/src/controllers/testMonitorController.ts, backend/src/routes/testMonitor.ts</files>
  <action>
Add two new controller methods and routes:

1. `POST /api/test-monitor/replay/flowise` - Controller: `replayThroughFlowise`
   - Body: `{ traceId: string, flowiseConfigId?: number }`
   - Calls flowiseReplayService.replayThroughFlowise()
   - Returns FlowiseReplayResult
   - Include `limitations` array in response explaining session state differences

2. `POST /api/test-monitor/replay/cloud9-direct` - Controller: `testCloud9Direct`
   - Body: `{ observationId: string }`
   - Calls cloud9DirectService.testCloud9Direct()
   - Returns Cloud9DirectResult with bottleneck classification
   - Returns 400 if observation not found or has no output

Add routes in testMonitor.ts after existing replay routes. Follow same error handling pattern (try/catch, res.status(500).json({error})).

Also add a summary endpoint:
3. `GET /api/test-monitor/replay/modes` - Returns available replay modes:
   ```json
   {
     "modes": [
       { "id": "live", "name": "Live Replay", "endpoint": "/replay", "description": "Replay tool call against live Node-RED" },
       { "id": "mock", "name": "Mock Replay", "endpoint": "/replay/mock", "description": "Replay with captured Cloud9 responses" },
       { "id": "flowise", "name": "Flowise Replay", "endpoint": "/replay/flowise", "description": "Re-send caller messages through Flowise" },
       { "id": "cloud9-direct", "name": "Cloud9 Direct", "endpoint": "/replay/cloud9-direct", "description": "Test Cloud9 API directly with trace parameters" }
     ]
   }
   ```
  </action>
  <verify>TypeScript compiles: `cd backend && npx tsc --noEmit`</verify>
  <done>Three new endpoints registered. /replay/flowise sends caller messages. /replay/cloud9-direct tests Cloud9 API. /replay/modes lists all replay options.</done>
</task>

</tasks>

<verification>
1. `cd backend && npx tsc --noEmit` passes
2. All new endpoints registered in routes
3. flowiseReplayService.ts and cloud9DirectService.ts exist with exported functions
</verification>

<success_criteria>
- Flowise replay re-sends caller messages and produces comparison with original trace
- Cloud9 direct test calls the production API and classifies bottleneck as cloud9 vs tool_logic
- All replay modes discoverable via /replay/modes endpoint
</success_criteria>

<output>
After completion, create `.planning/phases/05-replay/05-02-SUMMARY.md`
</output>
